{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing required library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import dlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_gamma(image, gamma=1.0):\n",
    "\n",
    "    invGamma = 1.0 / gamma\n",
    "    table = np.array([((i / 255.0) ** invGamma) * 255\n",
    "      for i in np.arange(0, 256)]).astype(\"uint8\")\n",
    "\n",
    "    return cv2.LUT(image, table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Strat the webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "\n",
    "\n",
    "predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "while True:\n",
    "    #Reading Frames\n",
    "    _, frame = cap.read()\n",
    "    \n",
    "    #Smoothing the frame pixels\n",
    "    frame = cv2.bilateralFilter(frame, 3, 175, 175)\n",
    "    \n",
    "    #Detecting faces in webcam\n",
    "    faces = detector(frame)\n",
    "    \n",
    "    #Saving the coordinate of detected face in x1,x2,y1,y2\n",
    "    for face in faces:\n",
    "        x1 = face.left()\n",
    "        y1 = face.top()\n",
    "        x2 = face.right()\n",
    "        y2 = face.bottom()\n",
    "\n",
    "        #Predicting the face landmark on the detected face\n",
    "        landmarks = predictor(frame, face)\n",
    "        l=[]\n",
    "        #Saving the landmark around the eyes in var l\n",
    "        for n in range(36, 48):\n",
    "            x = landmarks.part(n).x\n",
    "            y = landmarks.part(n).y\n",
    "            l.append((x,y))\n",
    "    #Diving the landmarks into left and right eye        \n",
    "    lefteye=l[0:6]\n",
    "    righteye=l[6:12]\n",
    "    lefteye=np.array(lefteye)\n",
    "    righteye=np.array(righteye)\n",
    "    \n",
    "    #Taking convex hull of both eyes\n",
    "    leftEyeHull = cv2.convexHull(lefteye)\n",
    "    rightEyeHull = cv2.convexHull(righteye)\n",
    "    \n",
    "#     #Creating a mask of same size as the frame\n",
    "#     mask = np.zeros(frame.shape, dtype=frame.dtype)  \n",
    "\n",
    "    \n",
    "    #Calculating the center of left and right eye hull\n",
    "    M1 = cv2.moments(leftEyeHull)\n",
    "    cX1 = int(M1[\"m10\"] / M1[\"m00\"])\n",
    "    cY1 = int(M1[\"m01\"] / M1[\"m00\"])\n",
    "    M2 = cv2.moments(rightEyeHull)\n",
    "    cX2 = int(M2[\"m10\"] / M2[\"m00\"])\n",
    "    cY2 = int(M2[\"m01\"] / M2[\"m00\"])\n",
    "    \n",
    "    center1=(cX1,cY1)\n",
    "    center2=(cX2,cY2)\n",
    "    \n",
    "    #Reading the image contaning anime eyes\n",
    "    src = cv2.imread('eyes.jpg')\n",
    "    src = cv2.bilateralFilter(src, 3, 175, 175)\n",
    "    \n",
    "    #Creating a mask of same size as the src image\n",
    "    src_mask = np.zeros(src.shape, src.dtype)\n",
    "    #Specifying the roi of the image for left eye\n",
    "    poly = np.array([ [12,16], [27,12], [70,15], [81,22], [86,35], [82,41], [62,47],[35,44],[21,33]], np.int32)\n",
    "    src_mask = cv2.fillPoly(src_mask, [poly], (255, 255, 255))\n",
    "    \n",
    "    \n",
    "    \n",
    "    src_mask2 = np.zeros(src.shape, src.dtype)\n",
    "    \n",
    "    #Specifying the roi of the image for right eye\n",
    "    poly2 = np.array([ [156,31], [165,22], [163,23], [191,10], [211,12], [222,14],[230,17] ,[213,40],[190,45],[173,45],[162,42]], np.int32)\n",
    "    src_mask2 = cv2.fillPoly(src_mask2, [poly2], (255, 255, 255))\n",
    "    \n",
    "    #Scale the image to your eye size\n",
    "    scale_percent = 50 # percent of original size\n",
    "    width = int(src.shape[1] * scale_percent / 100)\n",
    "    height = int(src.shape[0] * scale_percent / 100)\n",
    "    dim = (width, height)\n",
    "    # resize image\n",
    "    src = cv2.resize(src, dim, interpolation = cv2.INTER_AREA)\n",
    "    src_mask = cv2.resize(src_mask, dim, interpolation = cv2.INTER_AREA)\n",
    "    src_mask2 = cv2.resize(src_mask2, dim, interpolation = cv2.INTER_AREA)\n",
    "\n",
    "    output = cv2.seamlessClone(src,frame , src_mask, center1, cv2.NORMAL_CLONE)\n",
    "\n",
    "    output=cv2.seamlessClone(src, output, src_mask2, center2, cv2.NORMAL_CLONE)\n",
    "    \n",
    "    gamma = 1.8  # change the value here to get different result\n",
    "    adjusted_output = adjust_gamma(output, gamma=gamma)\n",
    "\n",
    "\n",
    "    #output the frame\n",
    "    cv2.imshow('Frame', adjusted_output)\n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
